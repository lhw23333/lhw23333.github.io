[TOC]   
### 操作系统引论    
https://blog.csdn.net/LonelyPlanet_/article/details/89115669#_463  
https://www.bilibili.com/video/BV1YE411D7nH?p=36
##### 操作系统的特性（并共虚异）  
1. 并发：同一段时间内多个程序执行
2. 共享：系统中的资源可以被内存中多个并发执行的进线程共同使用
3. 虚拟：通过时分复用（虚拟处理器）以及空分复用（如虚拟内存），把一个物理实体虚拟为多个  
虚拟内存使得应用程序认为它可以拥有连续的内存（一个连续完整的地址空间），而实际上它通常被分割成多个物理内存碎片  
优点：1.提高内存利用率  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.读写内存的安全性问题  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;物理内存本身是不限制访问的，任何地址都可以读写，而现代操作系统需要实现不同的页面具有不同的访问权限，例如只读的数据等等  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3. 进程间的安全问题   
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;各个进程之间没有独立的地址空间，一个进程由于执行错误指令或是恶意代码都可以直接修改其它进程的数据，甚至修改内核地址空间的数据，这是操作系统所不愿看到的  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4. 内存读写的效率问题  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当多个进程同时运行，需要分配给进程的内存总和大于实际可用的物理内存时，需要将其他程序暂时拷贝到硬盘当中，然后将新的程序装入内存运行。由于大量的数据频繁装入装出，内存的使用效率会非常低  


4. 异步：系统中的进程是以走走停停的方式执行的，且以一种不可预知的速度推进
##### 操作系统的主要功能
1. 进程管理  
进程控制，进程同步，进程通信和进程调度
2. 内存管理  
内存分配，内存保护，地址映射，内存扩充
3. 设备管理  
管理所有外围设备，包括完成用户IO请求，为用户进程分配IO设备，提高IO设备利用率，提高IO速度，方便IO使用  
4. 文件管理  
管理用户文件和系统文件，方便使用的同时保证安全性。包括磁盘存储空间管理，目录管理，文件读写管理以及文件共享及保护
5. 提供用户接口  
程序接口（如API）和用户接口（如GUI）






##### 各种操作系统的区别
1. 批处理操作系统：成批处理、系统吞吐量高、资源利用率高、没有人机交互功能，用户不能干预作业的执行
2. 分时操作系统：多路性、独立性、及时性、交互性 
3. 实时操作系统：及时响应、快速处理、高可靠性和安全性、不要求系统资源利用率  
操作系统的主要组成部分：进程和线程的管理、存储管理、设备管理、文件管理

##### 动态链接库与静态链接库的区别
静态链接库是.lib格式的文件，一般在工程的设置界面加入工程中。程序编译时，会把lib文件代码加入到程序中，因此会增加代码大小。不能手动移除lib代码。

动态链接库是程序运行时动态装入内存的模块，格式为.dll，在程序运行是可以随意加载和移除，节省内存空间。  

  
### 进程与线程

#### 进程
PCB，程序段，数据段三部分构成了进程实体（进程映像）
- PCB是进程存在的唯一标志
- 进程是程序的一次执行过程
- 进程是一个程序及其数据在处理机上执行时所发生的活动
- 时系统进行资源分配和调度的独立单位

##### 进程的组织方式
链接方式：
- 按照进程状态将PCB划分为多个队列
- 操作系统持有指向各个队列的指针
索引方式：
- 根据进程状态的不同，建立几张索引表
- 操作系统持有指向各个索引表的指针

##### 进程的三种基本状态
- 运行态，占有CPU，并在CPU上运行
- 就绪态，已经具备运行条件，但由于没有空闲CPU，而暂时不能运行
- 阻塞态，因等待某一事件而暂时不能运行

##### 进程控制
进程通过原语实现    
![image](https://images2015.cnblogs.com/blog/616953/201606/616953-20160619213048991-866706486.png)
![image](https://img-blog.csdnimg.cn/20210101215145924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDIzNTk3NQ==,size_16,color_FFFFFF,t_70)

##### 引起进程创建的事件
- 用户登录：
- 作业调度：多批道处理系统，在有新作业放入内存的时候，会为其建立一个进程
- 提供服务：用户向操作系统提出某些请求时，会新建一个进程处理该请求
- 应用请求：由用户进程主动请求创建一个子进程

##### 进程的阻塞和唤醒
阻塞：
- 找到对应PCB
- 保存上下文，PCB状态设置为阻塞态，暂时停止进程运行
- 将PCB插入相应事件的等待列表  

引起阻塞的事件：
- 等待系统分配某种资源
- 需要等待互相合作的其他进程完成工作
  
唤醒：
- 找到对应PCB
- 从等待队列移除，PCB该为就绪态
- PCB插入就绪队列，等待调度  

唤醒事件：
- 等待事件的发生

##### 进程的切换
![image](https://pic2.zhimg.com/80/v2-5672054f97fd77f78420fed6b442536e_720w.jpg?source=1940ef5c)

切换原语：
- 当前上下文信息存入PCB
- 放入相应队列
- 更新新的PCB
- 恢复上下文，新进程所需的运行环境
- 切换页表，使用新的虚拟内存


引起进程切换的事件：
- 当前时间片用完
- 更高优先级的进程到达
- 当前进程主动阻塞
- 当前进程终止


##### 进程的通信方式
1. 管道：
- 各个进程要互斥的访问管道  
- 管道是用于连接读写进程的一个文件，其实就是在内存中开辟一个大小固定的缓冲区
- 数据以字符流的形式写入管道，当缓冲区满时write()系统调用会被阻塞，管道空时，read()调用会被阻塞
- 数据一旦被读出，缓冲区就会删除此数据，避免读错数据的情况
分为三种：普通管道PIPE、命名管道NAME_PIPE、流管道S_PIPE  
普通管道为半双工，只能单向传输，只能在父子进程间使用  
流管道去除了第一种限制，可以双向传输  
命名管道去除了第二种限制，可以在许多并不相关的进程之间进行通讯
2. 系统IPC（包括消息队列、信号量、共享内存）  
信号量是一个计数器，用来控制多个进程对资源的访问，通常作为一种锁机制  
消息队列是消息的链表，存放在内核中并由消息队列标识符标识  
信号（也叫事件）是一种比较复杂的通信方式，用于通知接受进程某个事件已经发生  
共享内存是映射一段能被其他进程访问的内存，这段共享内存由一个进程创建，但是多个进程可以访问。共享内存是最快的IPC方式  
3. SOCKET  
套接口也是一种进程间通信机制，它可用于不同主机间的进程通信

##### 进程调度
从就绪队列中通过一定算法选择一个进程，并将处理机分配给他运行。
- 高级调度（作业调度）：从外存上处于后备队列的作业中挑选一个作业，分配内存等必要资源，并建立相应的进程（PCB），使他们获得竞争处理机权限的资格
- 外存->内存（面向作业），，，无->创建态->就绪态
- 中级调度：暂时不调用的进程调至外存等待，而PCB会一直常驻内存，会记录进程数据在外存中的位置，这种状态称之为（挂起），中级调度就是决定将处于哪个处于挂起状态的进程重新调入内存。频率比高级调度更高
- 外存->内存（面向进程），，，挂起态->就绪态（阻塞挂起->阻塞态）
- 低级调度：从就绪队列中选取进程，并分配处理机，进程调度是操作系统中最基本的一种调度
- 内存->CPU，，，就绪->运行态

###### 进程调度的时机
主动放弃：
- 进程正常终止
- 运行过程发生异常终止
- 主动请求阻塞（请求io）

被动放弃：
- 分给进程的时间片用完
- io中断，发生中断
- 更高优先级的进程进入就绪队列

非抢占调度：  
只允许主动放弃处理机，即使有更紧迫的任务出现，也会暂时阻塞，直到该进程终止或者主动放弃。  

抢占方式： 
有更紧迫进程需要处理机时，会立刻暂停，移交处理机

什么时候不能进程调度？
- 处理中断过程中
- 进程在操作系统内核程序临界区中
- 原子操作中

###### 调度算法
先来先服务（FCFS）：非抢占算法，等待时间越久的越优先得到服务  
- 优点：公平，算法实现简单
- 缺点：排在长作业后面的短作业需要等待很长时间，带权周转时间过长，对短作业用户体验不好。即对长作业有利，对短作业不利  
- 不会导致某个进程长期得不到服务（饥饿）
短作业优先（SJF）：非抢占式算法，追求最少的平均等待时间，最少的平均周转时间
- 优点：“最短的”平均等待时间，平均周转时间
- 缺点：不公平，对短作业有利，对长作业不利，可能产生饥饿现象
- 可能导致饥饿现象
高响应比优先（HRRN）：非抢占算法，综合考虑进程的等待时间和要求服务的时间，调度时先计算进程的响应比，选择响应比最高的进程为其服务，响应比 = （等待时间 + 要求服务时间）/ 要求服务时间
- 优缺点：综合考虑了等待时间和运行时间
- 对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题。
 

###### 时间片轮转
- 时间片不能过大，否则会退化为先来先服务（FCFS）的情况，会增大进程响应的时间。
- 时间片页不能过小，不然会频繁的切换进程，会有冗余的时间开销
- 抢占算法，通过时钟装置发出始时钟中断来通知CPU时间片以及用完
- 优点：公平，响应块，适用于分时操作系统
- 缺点：由于高频率的进程切换，因此有一定开销，不区分任务的紧急程度
- 不会饥饿

###### 优先级调度
- 越来越多的应用场景下，需要根据任务的紧急程度来决定处理顺序。
- 调度时选择优先级最高的作业/进程
- 既可以用于作业调度，也可用于进程调度，甚至还会用于io调度
- 既有抢占也有非抢占
- 优点：用优先级区分紧急程度，重要程度，适用于实时操作系统。可灵活地调整对各种作业/进程的偏好程度。
- 缺点：若源源不断地有高优点级进程到来，则可能导致饥饿
- 会饥饿

###### 多级反馈调度算法
- 对其他算法的折衷权衡
- 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
- 新进程到达时先进入第一级，按照FCFS原则排队等待被分配的时间片，若时间片用完进程还未结束，则进程进入下一级队列队尾。
- 只有第k级队列为空时，才会为k+1队列头的进程分配时间片用于进程调度
- 抢占式算法，在k级队列的进程运行过程中，若更高级中进入一个新进程，新进程则会抢占处理机，原来运行的进程放回k级队列队尾
- 优点：对各类型进程相对公共（FCFS），新进程都可以较快得到响应（RR），短进程有利（SPF），可以灵活的调整对各类进程的偏好程度，比如CPU密集型进程，io密集型进程
- 会饥饿

##### 进程同步机制
信号量机制
1. 信号量只能进行初始化，p,v操作
2. 临界区之前执行P(mutex)
3. 临界区之后执行V(mutex)
4. 对不同的临界区资源需要设置不同的互斥信号量。P，V操作必须成对出现，缺少V操作会导致资源永不被释放，等待进程用不被唤醒。

##### 生成者消费者
系统中有一组生成者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。生产者，消费者共享一个初始为空，大小为n的缓冲区。  
只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待。  
只有缓冲区不空时，消费者才能从中取出产品，否则必须等待。  
缓冲区时临界资源，个进程必须互斥的访问.  
- semaphore mutex = 1;
- semaphore empty = n; 
- semaphore full = 0;


```
producer ()
{
    while(1)
    {
        P(empty);
        P(mutex);
        //把产品放入缓冲区
        V(mutex);
        V(full);
        //增加一个产品
    }
}
```

```
consumer ()
{
    while(1)
    {
        P(full);
        P(mutex);
        //从缓冲区取出一个产品
        V(mutex);
        V(empty);
        //使用一个产品
    }
}
```
多生成者多消费者问题（吃水果）  
- semaphore mutex = 1;
- semaphore apple = 0;
- semaphore orange = 0;
- semaphore plate = 1;

```
dad()
{
    while(1)
    {
        //准备一个苹果
        P(plate);
        P(mutex);
        //把苹果放入盘子
        V(mutex);
        V(apple);
    }
}

mom()
{
    while(1)
    {
        准备一个橘子；
        P(plate);
        把橘子放入盘子；
        V(orange);
    }
}

doughter()
{
    while(1)
    {
        P(apple);
        //从盘中取出苹果
        V(plate);
        //吃掉苹果
    }
}

son()
{
    while(1)
    {
        P(orange);
        //从盘中取出橘子
        V(plate);
        //吃掉橘子
    }
}
```

##### 哲学家就餐问题 
5位哲学家对中间筷子的访问是互斥关系  
这个问题只有互斥关系，但每个哲学家进程需要同时持有两个临界资源才能开始吃饭，如何避免临界资源分配不当造成的自锁现象。
①每次最多允许4个哲学家同时进餐  
②要求奇数先拿左边，然后再拿右边，偶数相反，这样可以保证相邻奇偶中只有一个拿起筷子，另一个会直接阻塞，避免了死锁问题

```
semaphore chopstick[5] = {1,1,1,1,1};
semaphore mutex = 1;
Pi()
{
    while(1)
    {
        P(mutex);
        P(chopstick[i]);
        P(chopstick[(i + 1) % 5]);
        V(mutex);
        吃饭
        V(chopstick[i]);
        V(chopstick[(i + 1) % 5]);
        思考
    }
}
```

##### 死锁及其产生条件  
在两个或者多个并发进程中，如果每个进程持有某种资源，又等待其他进程释放它目前持有的资源，在未改变这种状态之前，都不能向前推进。这一情况被称作死锁。  
  
###### 什么时候会发生死锁
- 对不可剥夺资源的竞争，比如打印机
- 进程推进顺序非法。请求和释放资源的顺序不当，比如并发进程P1，P2分别申请资源R1，R2，之后进程P1有紧接着申请资源R2，而进程P2又申请资源R2，两者会因为申请的资源被对方占有而阻塞，从而发生死锁
- 信号量的使用不当

###### 死锁产生的四个条件
1. 互斥条件：一个资源一次只能被一个进程使用
2. 请求与保持条件：一个进程因请求资源而阻塞时，对其自身拥有的资源保持不放
3. 不可剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺
4. 循环等待条件：若干进程之前形成一种头尾相接的环形等待资源关系  
  
解决死锁的基本方法：预防死锁，避免死锁，检测死锁，解决死锁 
1. 预防死锁：确保死锁发生的四个必要条件中，至少有一个不成立
2. 避免死锁：动态检测资源分配状态，确保循环等待条件不成立，使系统处于安全状态
3. 解决死锁：包括进程终止和资源抢占  
&nbsp;1.选择一个牺牲品  
&nbsp;2.回滚  
&nbsp;3.饥饿（使回滚得越多的，越不可能继续作为牺牲品）

预防死锁  
1. 互斥条件：SPOOLing技术
2. 不可剥夺条件：  
当某个进程新的资源请求得不到满足时，释放自己所占有的资源，待以后重新申请。  
当某个进程需要的资源被其他进程占有时，由操作系统协助，来将其他进程的资源剥夺。需要考虑各进程的优先级
3. 破坏请求和保持：对自身资源保持不放。一次分配好所有需要的资源，再去运行，缺点是可能会导致饥饿
4. 循环等待：  
顺序编号：规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完  
原理分析：只有已占用小编号资源时，才有资格申请编号更大的资源

避免死锁（银行家算法）  
安全序列就是按照这种序列分配资源，则每个进程都能顺利进行，只要能找到一个安全序列，如果系统处于安全状态，则不会死锁，如果没有处于安全状态，则由可能死锁，在资源分配前判断系统是否会处于不安全状态，一次决定是否分配资源。   
最大需求矩阵MAX，分配矩阵Allocation，最大需要矩阵Need    
①如果Request[j]<=Need[i,j],便转向②；否则认为出错  
②如果Request[j]<=Avaliable[j],便转向③；否则表示无足够多资源，Pi必须等待  
③系统试探着把资源分配给进程Pi，并修改相关的数据（并非真的分配，修改数值只是为了预判）  
Available = Available - Request;  
Allocation[i,j] = Allocation[i,j] + Request[j];  
Need[i,j] = Need[i,j] - Request[j];  
④操作系统执行安全性算法，检测此次资源分配后，系统是否处于安全状态。若安全才进行分配，否则恢复数据，等待阻塞。  
安全算法：  
检查当前的剩余可用资源是否能够满足某个进程的最大需求，如果可以，就把该进程加入安全队列，并把该进程持有的资源全部回收。不断重复，看是否能让所有进程都加入安全队列。  

死锁的检测  
分配边和请求边，若不能消除所有边，那么此时系统死锁。接触死锁的方式
1. 资源剥夺法：挂起某些死锁进程，并抢占他的资源，将资源分配给其他进程。
2. 撤销进程法。强制撤销，代价过大
3. 进程回退，一个或者多个进程回退到足以避免死锁的地步。这就要求系统记录历史信息，设置还原点，不易实现。


#### 协程
线程：抢占式调度  
协程：协同式调度，避免了无意义的调度，可以提高性能，但程序员必须要自己承担调度的责任。协程也失去了标准线程使用多CPU的能力。
#### 用户空间和核心空间  
##### 为什么引入用户态和核心态
- 特权指令和非特权指令，os通过当前状态来判断是否可以执行特权指令，即用户态和内核态。
- 通过程序状态寄存器标记当前状态，0为用户态，1为核心态

操作系统为了支持多个应用同时运行，需要保证不同进程之间相对独立（一个进程的崩溃不会影响其他的进程 ， 恶意进程不能直接读取和修改其他进程运行时的代码和数据）。 因此操作系统内核需要拥有高于普通进程的权限， 以此来调度和管理用户的应用程序。
运行在用户态下的程序，只能受限地访问内存，不允许访问外围设备。占用CPU的能力被剥夺，CPU资源可以被其他程序获取。    
运行在内核态下的程序，可以访问内存所有数据，包括外围设备。

##### 操作系统内核的主要功能
- 时钟管理：负责计时功能
- 中断处理：负责实现中断机制
- 原语 ①是一种特殊的程序。②处于操作系统最底层，最接近硬件的部分。③具有原子性。④运行时间短，调用频繁。
- 资源管理，进程管理，存储器管理，设备管理

##### 中断和异常
- CPU收到计时部件发出的中断信号，切换为核心态对中断进行处理
- 中断发生时，CPU立即进入核心态
- 中断发生后，当前进程暂停运行，由操作系统内核对中断进行处理
- 对应不同的中断信号，会进行不同的处理
- 发生中断时，CPU从用户态切换到核心态
- 有了中断才能实现多道程序并发执行

###### 内中断（异常）
信号来自CPU内部
- 系统调用
- 硬件故障（缺页）
- 软件中断

###### 外中断
信号来自CPU外部
- 外设请求（io操作完成发送中断信号）
- 人工干预（强行终止一个进程） 


###### 用户态切换到内核态的三种方式：
中断是唯一一个从用户态切换到内核态的方式，以下都是中断的特殊方式.
1. 系统调用：用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用，申请使用操作系统提供的服务程序，以完成工作。
2. 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，会触发由当前运行进程切换到处理此异常的内核相关程序中。因此也就转到了内核态，比如缺页异常。
3. 外围设备终端：外围设备完成用户请求的操作后，会像CPU发送相应的中断信号。此时，CPU会暂停执行下一条即将要执行的指令，转而执行与中断信号对应的处理程序。如果先前执行的指令是用户态的程序，那么转换的过程自然就发生了由用户态到内核态的转换。


##### 程序和进程的区别
1. 程序是一个静态概念，进程是一个动态概念
2. 程序没有并行特征，而进程有并行特征
3. 程序不会竞争计算机系统资源，而进程是竞争计算机系统资源的基本单位
4. 不同的进程可以包含同一程序，只要该程序所对应的数据集不同

#### 线程
##### 进程和线程，以及它们的区别  
- 调度：线程是调度分配的基本单位，进程是拥有资源的基本单位
- 并发性：线程并发执行效率更高，每个线程可以占用不同的CPU，每个线程都有一个线程ID和一个线程控制块TCB
- 拥有资源：线程仅有少量资源来完成运行需求，不拥有系统资源
- 独立性：线程独立性更低
- 系统开销：切换线程系统开销低
1. 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位
2. 线程是进程的一个实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位
3. 一个进程可以有多个线程，多个线程可以并发运行
4. 线程基本不拥有系统资源，只拥有一些在运行中必不可少的资源，比如程序计数器、寄存器和栈
5. 但线程可以与其他线程共享进程所拥有的全部资源
6. 线程可以创建和撤销另一个线程

##### 用户级线程和内核级线程
用户线程：
- 通过线程库实现，线程管理包括线程切换由应用程序进行管理（用户空间），无需系统调用。
- 对应操作系统来说只有只有一个进程需要执行和管理
- 优点：不需要切换到内核态，线程管理的系统开销小，效率高。
- 缺点：当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高，多个线程不能在多核处理机上运行
![image](https://img-blog.csdnimg.cn/20210102002230131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDIzNTk3NQ==,size_16,color_FFFFFF,t_70)

内核级线程；
- 线程的管理工作由内核完成，线程切换都必须在内核态下完成
- 内核可以看见多个线程
- 优点：当一个线程被阻塞时，其他线程还可以继续执行，并发性强，多线程可以在多处核理机上执行。
- 缺点：一个用户进程会占用多个内核线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理成本大，开销大。
![image](https://img-blog.csdnimg.cn/2021010200221523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDIzNTk3NQ==,size_16,color_FFFFFF,t_70)

两者结合：
- n个用户级线程映射到m个内核级线程上
- 客服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核线程，开销过大的缺点。
![image](https://img-blog.csdnimg.cn/20210102004245960.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDIzNTk3NQ==,size_16,color_FFFFFF,t_70)

##### 多线程共享什么数据
- 进程代码段
- 进程的公有数据
- 进程打开的文件描述符
- 信号的处理器
- 进程的当前目录
- 进程用户ID与进程组ID

##### 线程同步的方式
1. 信号量    
允许统一时刻多个线程访问同一个资源，但需要控制统一时刻访问此资源的最大线程数量
2. 互斥量  
实际上是信号量的一种特殊情况，允许统一时刻只有一个线程访问同一个资源
3. 信号，也叫事件  
通过通知操作的方式来保证多线程同步，还可以方便实现多线程优先级的比较操作

##### 多线程锁实现多线程同步
1. 互斥锁  
保护临界区，确保同一时间，只有一个线程访问数据  
如果互斥量已经上锁，调用线程会阻塞，直到互斥量被解锁
2. 自旋锁
在获取到锁之前，一直处于循环检测保持者是否已经释放了锁。  
与互斥锁的区别是，在申请自旋锁时，线程处于忙等状态，而非挂起状态
3. 信号量
一个计数器，用来控制多个进程对共享资源的访问。  
互斥锁为信号量的一个特殊情况。
4. 读写锁
高级别锁，区分读和写，符合条件时，允许多个线程访问对象。  
处于读锁时，允许其他线程和本线程的读锁，但不允许写锁。  
处于写锁时，任何锁操作都会睡眠等待  
5. 递归锁   
递归锁是互斥锁的一个特殊情况。同样地，只能由一个线程访问该对象，但允许同一个线程在未释放其拥有的锁时，反复对锁进行加锁操作



##### 线程的状态

线程的状态

状态 | 含义 
---|---
创建 | 还未开始的线程，处于此状态
就绪 | 正在Java虚拟机里面执行的线程，处于此状态
阻塞 | 该线程阻塞于锁
等待 | 进入该状态的线程需要等待其他线程做出一些特定动作，比如通知或中断
超时等待 | 该状态不同于等待，在该状态的线程，只会在一个特定时间内等待其他线程执行特定动作。若其他线程一直不执行，它可自行返回
终止 | 已经结束的线程，处于此状态




##### 临界区  
每个进程中，访问临界资源的那段程序块被称为临界区。每次只准许一个进程进入临界区，进入后不允许其他进程进入。  
1. 若有若干进程要求进入空闲临界区，一次仅允许一个进程进入
2. 若已有进程进入临界区，其他进程必须等待
3. 进入临界区的进程必须在有限时间内退出
4. 如果进程不能进入临界区，则必须让出CPU
  
##### 中断和轮询
中断指的是，在计算机执行期间，系统内发生任何非寻常或非预期的急需处理时间，使得CPU中断当前正在执行的程序，而转去执行相应的事件处理程序。处理完毕后，处理器又返回原来被中断的地方，继续执行或调度新的进程。

轮询指的是，系统定时对各种设备轮流询问一遍是否有处理要求。有要求的，则加以处理。轮询占据了CPU相当一部分处理时间，是一种效率较低的 方式。    
中断：容易遗漏一些问题，CPU 利用率高  
轮询：效率低，等待时间长，CPU利用率低

##### 同步异步和阻塞非阻塞的理解  
同步/异步关注的是消息通信机制，阻塞一般针对进程是否可以工作来理解，所以这两种概念和直觉理解是相反的，同步和阻塞对应，异步和非阻塞对应
- 阻塞式发送（blocking send）. 发送方进程会被一直阻塞， 直到消息被接受方进程收到。
- 非阻塞式发送（nonblocking send）。 发送方进程调用 send() 后， 立即就可以其他操作。
- 阻塞式接收（blocking receive） 接收方调用 receive() 后一直阻塞， 直到消息到达可用。
- 非阻塞式接受（nonblocking receive） 接收方调用 receive() 函数后， 要么得到一个有效的结果， 要么得到一个空值， 即不会被阻塞。

##### 5种I/O模式
缓存I/O访问分为两个步骤
1. 等待数据访问
2. 将数据拷贝到进程之中
I/O模式
- 阻塞I/O    
用户程序read时，若数据还没有准备好，进程则阻塞，等待准备好后拷贝数据，返回结果后解除阻塞
- 非阻塞I/O  
直接返回error，用户进程知道还没有准备好，然后==不断的主动询问==是否准备好
- I/O多路复用（轮询）  本质是同步I/O
类似轮询机制，用户进程调用==select==时整个进程会被==block==，这是系统会监视所有连接的socket，当任何一个socket中的数据准备好后，select就会返回  
特点是：通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中任意一个进入就绪状态，select（）函数就可以返回  
多路复用的效率并不一定比阻塞高，select的优势在于能同时处理多个连接    
1. select   
select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。主要的问题有每次调用都需要将fd数组从用户态拷贝到内核态；它仅仅知道有I/O事件发生了，却并不知道是哪那几个流，只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作；而且，Select支持的文件描述符太少，一般32位系统为1024个，虽然可以通过FDSET宏修改，但是fd太多效率会明显降低。优势就是良好的跨平台性，几乎所有的平台都支持select，对于链接数量较少的情况表现还是不错的。
2. poll：  
poll本质上和select没有区别，它也是将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。相比Select他没有它没有最大连接数的限制（它是基于链表来存储的），不过大量的fd的数组被整体复制于用户态和内核地址空间之间，很多复制是没意义的。  
3. epoll:  
epoll的API有三个，可以良好的解决select与Poll的缺点。由于他可以在内核里面通过红黑树记录所有的socket，所以不需要每次调用都从头复制一遍（一般情况下，并发量远远小于实际链接数，从内核拷贝到用户的缓冲数据也并不是很多）。同时由于给socket句柄注册一个中断回调函数，所以不需要主动遍历。另外，epoll没有fd数量限制，它所支持的FD上限是最大可以打开文件的数目。

epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式，只支持非阻塞Socket。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无 论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误。epoll链接上限非常大（10万左右），不会随着fd的增加而降低效率，内存复制上开销也比较小

表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。



- 异步I/O  
用户进程发起read请求后直接返回，不会对用户进程产生任何block，等数据准备完成后，将数据拷贝到用户内存，一切完成后，向用户进程发送消息，告诉他read操作已经完成。

### 存储管理

##### 连续分配管理方式
###### 单一连续分配
在单一连续分配方式中，内存被分为系统区和用户区。系统区通常位于内存的低地址部分，用于存放操作系统相关数据：用户区用于存放用户进程相关数据。内存中只能有一道用户程序，用户程序独占整个用户区空间。  
优点：实现简单。无外部碎片。  
缺点：只能用于单用户，单任务的操作系统中；有】内部碎片，存储器利用率极低。
###### 固定分区分配
为了装入多道程序，将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业。  
通常需要建立一个数据结构--分区说明表，来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小，起始地址，状态（是否已分配）  
优点：实现简单，无外部碎片  
缺点：当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能；会产生内碎片，内存利用率低
###### 动态分区分配
动态分区分配又称可变分区分配。这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态的建立分区。并使分区的大小正好合适进程的需要。因此系统分区的大小和数目是可变的。    
常用的数据结构：空闲分区表，空闲分区链  
在回收内存资源时需要考虑到相邻合并问题，有时可能会将3个表项合并为一个表项  
没有内碎片，，但是会有外碎片  

###### 动态分区分配算法
- 首次适应算法   
空闲分区以地址递增次序链接，分配内存时顺序查找，找到大小能满足要求的第一个空闲分区
- 最佳适应算法  
空闲分区按容量递增的次序链接，找到第一个能满足要求的空闲分区
- 最坏适应算法  
空闲分区以容量递减的次序链接，找到第一个能满足要求的空闲分区，也就是挑选最大的分区
- 邻近适应算法  
无论低地址，高地址部分的空闲分区都有相同的概率被使用，导致高地址的大分区可能被使用，最后导致没有大分区可用，所以（首次适应算法）的效果反而更好

##### 基本分页方式
连续分配：为用户进程分配的必须是一个连续的内存空间  
非连续分配：为用户进程分配的可以是一些比较分散的空间  

基本分页存储的思想：把内存分为一个个相等的小分区，在按照分区大小把进程拆分成一个个小部分去放入内存，分配的分区不一定是连续的，可能是相隔很远的两个小分区共同分配给一个进程，所以内存分区越小，内碎片就越小，内存利用率就会更高一些。  

将内存空间分为一个个大小相等的分区，每一个分区就是一个页框，每个页框都有一个编号，即页框号。  
将用户进程的逻辑地址页分为和页框大小相等的一个个区域，称为“页面”。每个页面也有页号，页面和页框会一一对应起来  

###### 逻辑地址和物理地址的转换
如果是运行中转换的话，是通过重定位寄存器，模块在内存中的“起始地址” + 目标内存单元相对起始位置的“偏移量”，来计算出最终的物理地址  



##### Windows 下的内存管理
- 虚拟内存，适用于管理大型对象或者结构数组
- 内存映射文件，适用于管理大型数据流以及在单个计算机上运行多个进程之间的共享数据
- 内存堆栈，适用于管理大量小对象  
  
Windows 操纵内存可分为两个层面，分别为：  
- 物理内存
- 虚拟内存


##### 分页与分段的区别
- 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段，如代码段、数据段、堆栈段。每个进程有一个二维地址空间，相互独立，互不打扰。  
- 段式存储管理的优点是：没有内碎片，因为段大小可变，可以通过改变段的大小而消除内碎片。但会产生外碎片，比如4K的段换5K的段，会产生1K的外碎片
- 页式存储管理是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页，而物理内存划分为同样大小的帧。程序加载时，可将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。  
- 页式存储管理的优点是：没有外碎片，因为页的大小固定，但会产生内碎片，因为一个页可能填充不满


##### 缓冲区溢出及其危害
缓冲区溢出指的是，计算机向缓冲区填充数据时，超出了缓冲区本身的容量，溢出的数据覆盖在了合法的数据上。其危害有：
1. 程序崩溃，导致拒绝服务
2. 跳转并且执行一段恶意代码

##### 虚拟内存  
内存映射区

虚拟内存允许执行进程不必完全在内存中。  

每个进程拥有独立的地址空间，这个空间被分为大小相等的多个块，称为页。每个页都是一段连续的地址。这些页被映射到物理内存，但并不是所有页都在内存里才能运行程序。  

当程序引用到一部分在物理内存中的地址空间时，由硬件进行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，操作系统负责将缺失的部分装入物理内存，并重新执行失败的指令。   

虚拟内存的应用与优点:  
1. 在内存中可以保留多个进程，系统并发度提高
2. 解除了用户与内存之间的紧密约束，进程可以比内存的全部空间还大

##### 物理地址的管理
物理地址只有内存管理模块可以访问，内核空间和用户空间都不可以使用，当我们进行系统调用的时候，首先通过内核空间上的虚拟地址，通过映射表访问物理地址上保存的系统api和系统变量

##### 虚拟地址的管理  
用户空间和内核空间都是虚拟内存  
在32上虚拟分配4g内存的虚拟空间   
虚拟内存是进程独享的，且互不干扰的虚拟地址空间
不同的进程进入到内核后访问的是同一块内存

##### 虚拟地址和物理内存如何映射

###### 分段机制
分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。
![image](https://img-blog.csdnimg.cn/20201227182656910.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDIzNTk3NQ==,size_16,color_FFFFFF,t_70)

###### 分页机制
对于物理内存，操作系统把它分成一块一块大小相同的页，这样更方便管理，例如有的内存  
页面长时间不用了，可以暂时写到硬盘上，称为换出。一旦需要的时候，再加载进来，叫作换入。  
页大小为4kb，为了能够定位和访问每个
页，需要有个页表，保存每个页的起始地址，再加上在页内的偏移量，组成线性地址，就能
对于内存中的每个位置进行访问了。
![image](https://img-blog.csdnimg.cn/20201227182656875.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDIzNTk3NQ==,size_16,color_FFFFFF,t_70)

##### 堆和栈的区别  
程序的内存分配  
1. 堆：由程序员分配释放，若程序员不释放，程序结束时可能由操作系统回收
2. 栈：由编译器自动分配释放，存放函数的参数值、局部变量的值等等
3. 全局区/静态区  
- 全局变量和静态变量是放在一起的
- 初始化的全局变量和静态变量放在一个区域
- 未初始化的全局变量和静态变量放在另一个区域
- 程序结束时由系统释放
4. 文字常量区：常量字符串的存放位置，由操作系统在程序结束后释放 
5. 程序代码区：存放函数体的二进制代码


  
### 面试提问
1.问：谈谈对线程与进程的理解（提问概率：★★★★★）
首先说说基本概念，即进程是系统资源分配的基本单位，线程是CPU运算调度的基本单位。  

==进程：具体一点来讲，进程是装入内存运行的程序段，是许多可运行代码段以及系统资源的集合==。再贴切一点，进程是程序对系统数据资源进行处理操作的一次活动，我们平时用Windows打开任务管理器展示的都是一个个进程，他们在运行时常驻在内存里面根据程序的设计来调用与操作系统的资源与数据。（每个进程对应一个内核空间与用户空间，这是虚拟内存。内核空间的地址是固定的，进程通过虚拟内存映射到上面，内核空间内容不受用户控制，但是会通过系统调用改变其内部状态。）==之所以要用进程，是因为想要更好的实现多道程序设计技术（即多个相互独立的程序在内存中同时存放, 相互穿插运行, 宏观并行, 微观串行，现代PC操作系统都是采用这种技术，即分时操作系统）==  需要一个能对多个运行中的程序进行控制的实体，这个实体就是进程。进程在运行时会占用内存空间，一般分为内核空间与用户空间，内核空间包括进程的控制信.息、内核栈、内核代码等内容，用户空间则是常见的堆、栈、常量区数据等。用户对进程进行输入时进程都处于用户态，当进程执行某些系统调用的时候才会切换到内核态，才能操作内核空间，调用完成后进程又会切回到用户态。  
  
线程：在进程刚出现时还没有线程的概念，那时候进程其实也是执行CPU运算调度的基本单位，但是由于进程的创建成本与通信成本太高，才有线程的诞生。线程必须被包含在进程中，一个进程可以有很多线程（至少有一个作为主线程），这些线程有自己的资源（如栈，寄存器）也共享进程的许多资源。我们通常写的Main函数可以简单理解为一个进程的代码段，但是进一步来讲，其实他是该进程中主线程的代码段，每一个线程被创建时都会自动的分配栈资源、寄存器数据，这些数据只有该线程能访问，其寄存器的数据是保存在内核空间当中的。如果从主线程调用malloc等函数来申请堆内的空间，这个空间就不是自己所有的了，其他线程也可以访问的，因为他们同属同一个进程，因此同一进程内的线程可以方便的进行数据通信。

2.问：谈谈多线程的意义（提问概率：★★★★）  
简单总结就是两个词，并行与并发。所谓并发，就是多个任务流宏观上同时执行，实际微观上是顺序轮流执行，并发的概念产生的比较早，我们的分时操作系统就是基于这个原理。并行，是指多个任务真正的在多个处理器上面同时运行。  

单核：对于单核来说，多线程的执行就是并发，这时候开启多线程也是有意义的。首先大部分任务都不可能是完全CPU密集的，中间肯定穿插着很多IO操作，IO阻塞会造成整个程序被阻塞。，如果他阻塞了就会切换到游戏主线程，不影响游戏逻辑。第二，执行时间长的任务会影响带有GUI程序的用户体验。  

多核：对于多核来说，更在意并行，就是为了充分利用多个CPU的计算能力。前面提到了GUI与压缩任务，如果是单核机器，那么其实是GUI线程与压缩任务线程按时间片轮流执行，本质上并没有提高程序的运算效率（特别是对于压缩任务），反而由于多线程的频繁切换还可能增加了一定开销。如果这时候有多个CPU，就可能出现CPU1执行GUI逻辑的时候，CPU2处理压缩任务，达到了真正的并行

3.问：如何理解内核态与用户态（提问概率：★★★★）  
在现在操作系统中，内存分为内核空间与用户空间,内核功能模块运行在内核空间，而应用程序运行在用户空间。现代的CPU都具有不同的操作模式，代表不同的级别，不同的级别具有不同的功能，其所拥有的资源也不同，在较低的级别中将禁止使用某些处理器的资源。很多操作系统设计时都利用了这种硬件特性，使用了两个级别，最高级别和最低级别，内核运行在最高级别（内核态），这个级别几乎可以使用处理器的所有资源，而应用程序运行在较低级别（用户态），在这个级别的用户不能对硬件进行直接访问以及对内存的非授权访问。内核态和用户态有自己的内存映射，即自己的地址空间。  

当工作在用户态的进程想访问某些内核才能访问的资源时，必须通过系统调用或者中断切换到内核态，由内核代替其执行。进程上下文和中断上下文就是完成这两种状态切换所进行的操作总称。我将其理解为保存用户空间状态是上文，切换后在内核态执行的程序是下文。  

4.问：什么是进程上下文，中断上下文（提问概率：★★★）  
进程上下文：是指进程由用户态切换到内核态是需要保存用户态时cpu寄存器中的值，进程状态以及堆栈上的内容，以便再次执行该进程时，能够恢复切换时的状态，继续执行，进程上下文的信息保存在PCB里面。一般来说，进程上下文主要是异常处理程序和内核线程。内核之所以进入进程上下文是因为进程自身的一些工作需要在内核中做。例如，系统调用是为当前进程服务的，异常通常是处理进程导致的错误状态等。  

中断上下文：硬件通过中断触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。中断上文可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被中断的进程环境。  

5.问：并行与并发（提问概率：★★★★）  
并行是多个任务在严格同时运行，即在多个CPU核上面运行。  

并发是多个任务宏观同时运行，微观顺序串行运行，即在一个核上面分时间片轮流执行。  
##### 线程和协程
6.问：协程coroutines、纤程Fiber（提问概率：★★★）  
提到协程，我们最常见的描述就是，协程是用户态下的轻量级线程。不过这句话不足以阐述他的特性，我从下面几个方面来描述一下。  
- 我们知道线程的出现是为了减小进程的切换开销，提高多核的利用率。当程序运行到某个IO发送阻塞的时候，可以切换到其他线程去执行，这样不会浪费CPU时间。而线程的切换完全是通过操作系统去完成的，切换的时候一般会通过系统点用从用户态切换到内核态。这段话的重点是，线程是内核态的。
- 我们常见的代码逻辑都是被封装在一个个函数块里面。每次传递一个参数，这个函数就会从头到尾执行一遍，有对应的输出。如果在执行的过程中，发生了线程的抢占切换，那么当前线程就会保存函数当前的上下文信息（放到寄存器里面），去执行其他线程的逻辑。当这个线程重新执行时会根据之前保存的上下文信息继续执行。这段话的重点是，线程的切换需要保存函数的上下文信息。

- 而且现代操作系统一般都是抢占式的，所以多个线程在执行的时候在什么时候切换我们是无法控制的。所以，多线程编程时为了保证数据的准确性与安全性，我们经常需要加锁。这段话的重点是，线程的执行顺序我们无法控制，什么时候切换我们也几乎无法控制。

- 由于线程在运行时经常会由于IO阻塞（或者时钟阻塞）而放弃CPU，会导致我们的逻辑不能流畅的执行下去。所以，我们一般采用异步+回调的方式去执行代码。当线程与到阻塞时直接返回，继续执行下面的逻辑。同时注册一个回调函数，当内核数据准备好了之后再通知我们。这种写代码的方式其实不够直观，因为我们一般都习惯顺序执行的逻辑，一段代码能从头跑到尾那是再理想不过了。这段话的重点是，涉及到IO阻塞的多线程编程时，我们一般用异步+回调的方式来解决问题。     
  
**了解了上面的内容，我们就可以开始继续学习协程了。**
1. 协程是用户态的，他是包含在线程里面的，简答来说你可以认为一个线程可以按照你的规则把自己的时间片分给多个协程去执行。

2. 因为一个线程里面可能有多个协程，所以协程的执行需要切换，切换就需要保存当前的上下文信息（一组寄存器和调用堆栈，保存在自身的用户空间内），这样才能在再次执行的时候继续前面的工作。相比线程，协程要保存的东西都很少。

3. 相比线程，协程的切换时机是可以控制的。我们可以告诉协程，代码执行到哪句的时候切换到哪个协程，这样就可以避免线程执行不确定性带来的安全问题，避免了各种锁机制带来的相关问题。

4. 协程的代码看起来是同步的，不需要回调。比如说有两个协程，A协程执行到第3句就一定会切换到B协程的第4句，假如A与B里面都有循环，那展开来看其实就是A与B函数不断的顺序执行。这种感觉有点像并发，同样在一个线程上的A与B不断的切换去执行逻辑。

5. 协程不过是一种用户级别的实现手段，他并不像线程那样有明确的概念与实体，更像是一个语言技巧。他的切换开销小。  

7. 问：同步与异步，阻塞与非阻塞（提问概率：★★★★★）  
同步与异步

主要指消息通信的机制。

同步：一个函数在调用的时候，没有得到结果的情况下就不会返回。（如IO多路复用的Select、Poll、epoll，后面说）

异步：一个函数在调用的时候，都会立刻返回，没有返回结果，被调用者通过状态、通知、回调函数处理这个调用（如AIO、IOCP后面说）  

阻塞非阻塞  
主要是针对线程（或者说进程）的状态。（先给出一个简单但不完全准确的理解）  
阻塞就是线程（进程）停止执行，保存上下文，把cpu让出去，等待回调唤醒，但是后续逻辑不会执行。  
非阻塞就是线程在遇到不能立刻返回结果的情况（如发送缓冲区满了、临界区）时就立刻返回，让该线程可以继续执行其他任务，不会把CPU让出去，不会影响后面的执行逻辑。  

关于阻塞的进一步理解：  
阻塞的原因往往不是线程本身的原因，而且他想获取CPU以外的资源（如内存）时，发现这个资源目前获取不到（如内核迟迟不给他想要的信息），只能自己休息，等待资源到来再去执行。  
从用户的角度来看，阻塞确实就是把cpu让出去，等待回调唤醒。但是从操作系统来看，比如当我们执行某些系统调用的时候（如select），该线程只是表现是阻塞的，其实select会继续执行这个系统调用的相关工作（做一些与内核数据相关的内容等），CPU也并没有让出去。 





关于Socket编程中的阻塞与非阻塞  
Socket的发送与接收可以在编码时手动设置阻塞或者非阻塞。当我们用默认的阻塞方式发送socket数据时，操作系统里面会有一个内核缓冲区（属于内核区），当缓冲区满的时候你想要通过socket发送，当前的线程就会阻塞，因为你要等待他缓存区有位置才能添加到缓存区里面（如果这个sendto是在主线程调用，那么主线程就会阻塞，表现效果就是界面无响应），直到缓冲区发送出去清空后才会恢复。  

对于这个问题一般有3种解决方案：
1. 多线程 socket发送单独开放一个或多个线程，这样即使线程阻塞也不会影响主线程逻辑。
2. I/O多路复用 （select，poll，epoll） 虽然也可能会阻塞，但是由于可以监控多个socket，可以很大程度缓解这个问题
3. 异步I/O 如Windows上的IOCP，发出调用立刻返回，等待事件回调，不会出现阻塞问题

8.问：挂起（Suspend），睡眠（sleep、Wait），阻塞（Block）（提问概率：★★★）  
挂起是一种主动行为，因此恢复也应该要主动完成。  
 
睡眠也是一个主动行为，不过因为有设置睡眠时间，所以不需要主动恢复。  

而阻塞是一种被动行为（或者说是一个状态），是在等待事件或者资源任务的表现，你不知道它什么时候被阻塞，也不清楚它什么时候会恢复阻塞。  

挂起不释放CPU，如果任务优先级高，就永远轮不到其他任务运行。一般挂起用于程序调试中的条件中断，当出现某个条件的情况下挂起，然后进行单步调试    。  

睡眠中的Sleep也不释放CPU与锁，而Wait会释放CPU与锁。  

阻塞就是会释放CPU，其他任务可以运行，一般在等待某种资源或者信号量的时候出现。  

9.问：操作系统如何管理内存？如何解释虚拟内存？进程地址空间，堆、栈是什么样的（提问概率：★★★★★）  
一般操作系统分为内核区域与用户区，用户区对应的是虚拟内存，32位系统下0-4G。因为每个进程理论上都可以使用这个大小的内存，所以需要引入虚拟内存通过页处理转换到真正的物理内存上面。每个进程分为内存虚拟内存与用户虚拟内存，内核区有内核代码数据区（PCB等）。进程虚拟部分有堆，栈，bss，data初始化的全局静态，text代码段等。  
  
10.问：虚拟内存的意义（提问概率：★★★）  
1. 节省内存资源，拿出一部分硬盘空间来充当内存使用，动态替换加载
2. 使得应用程序在逻辑上认为它拥有连续的可用的内存，方便管理
3. 提高安全性，程序员只知道逻辑地址  


11. 问：操作系统内存为什么要分成堆与栈？二者功能上有什么差异？（提问概率：★★★）  
栈由编译器分匹配，空间小，Linux默认8M左右，WIndows默认1M左右（可以调整用户栈）。==栈主要用来存储函数调用堆栈信息，局部变量，函数调用参数等相关信息，速度快。==
  
我们想在==运行时控制存储数据结构的内存需求大小，以及其生命周期==，所以要有一个满足我们要求的空间，也就是堆。堆由大片的可利用的块或空闲组成，堆中的内存可以按照任意顺序分配和释放。堆的大小理论上与虚拟内存大小相差无几，但是实际上用户可用的堆要小很多。  

12.问：进程同步与线程同步（线程安全）（提问概率：★★★★★）     
线程同步 ： 互斥量，条件变量，读写锁，信号量  
由于线程的执行是基于时间片抢占的，所以我们不能确定线程的执行顺序，一旦多个线程操作一个共享资源的时候很可能由于执行顺序不一致（竞争条件）导致数据混乱，也可能有多个线程对资源同时进行修改（多线程多核情况下），所以需要一定的手段来协调不同线程的执行顺序、控制当前线程读取或修改资源的权限，从而保护资源数据。这个手段其实就是线程同步。

对于线程同步这里举个例子，一个全局变量Num执行Y=++Num，Y=++Num不是原子操作，其实在执行过程中分为读Num、写Num、赋值三个步骤。如果A线程在执行到Num++的时候，B线程给Num执行了++操作（或者说A线程Num++的时候被B线程抢占），那么Num其实执行了两次++。那么切换回去后Y的值也相当于Y = Num+2;。更关键的问题是，这个情况是一定概率下发生的，线程的切换以及执行顺序我们无法控制。这个例子其实不算严重，做多也就是数据出问题，不过有的涉及到指针删除操作的如果执行混乱可能导致程序崩溃，所以为了保证线程安全，我们要实现线程同步。

常见的同步方式有：临界区（Windows上属于用户模式下的一种实现方式，本质上是通过信号量实现，进程内部的线程同步）、互斥量（内核对象，可以跨进程同步，属于信号量的特例）、事件（内核对象，可以跨进程同步）、信号量（内核对象，可以跨进程同步）

13.问：什么是原子操作，什么是临界区（提问概率：★★★★）  
原子操作：就是计算机里不可拆分、不可中断的操作，要么执行完成，要么执行失败。例如：x = 1，其汇编指令是：mov 1,eax。x对应寄存器eax，一步到位，所以是原子操作。而X++，需要先读取x，如load eax,x（将x读入eax寄存器中），然后再去执行加1操作，分成两步，不是原子操作。  

临界区：是一个访问共享资源的程序代码段（共享资源包括：鼠标键盘设备或是一个用户态的堆内存等），这个代码段同一时刻只能被一个线程锁访问。当有一个线程进入临界区代码段时，其他线程或是进程必须等待。   

14.问：什么是竞争条件，为什么会产生，如何避免？（提问概率：★★★★★）  
由于多线程的执行顺序不同造成结果不同的情况叫做竞争条件race condition。竞争条件产生的根本原因就是因为多线程执行顺序的不确定性，如果没有合理的控制好线程之间的同步，那么就会造成竞争条件（例子在线程同步问题里有描述），严重的话就会造成进程崩溃。最常见的手段就是给可能产生竞争条件的代码区加锁（Mutex，本质是内核中的锁对象），使用临界区（Critical Section）。

当然，你还需要了解哪些地方的代码可能产生竞争条件。这个问题并不简单，有的时候我们往往会忽略掉一些特殊的情况，比如函数的返回值、引用的跨线程传递等。

15.问：乐观锁与悲观锁（提问概率：★★★）   
乐观锁先读取并处理(通过cpu提供的原子操作指令组成的CAS完成)，处理后看数据和处理人前一样不，一样表示没人动过可以改，否则拒绝(认为没有加锁)。

悲观就是认为不加锁一定会出问题，所以执行前必须先加锁后再处理。

16.问：生产者与消费者问题（提问概率：★★★★★）    
- 不过我们要保证存储室满的时候生产者要暂停生产，消费者每次去拿产品的时候存储室那里要有产品。   
- 就是有两个进程（线程），一个模拟生产者，一个模拟消费者，操作系统有一个缓冲区作为存储室，
- 跨机器通信用socket，一般使用阻塞的消息队列来模拟这个问题。    
- 对于线程，可以共享进程的内存来通信。也是通过阻塞的消息队列来模拟，生产者写到队列头，消费者取队列尾。

17.问：常见进程通信方式与原理（提问概率：★★★★★）  
进程间通信的本质是在内存开辟一块区域，然后两个进程通过这块内存进行信息交流。

管道（pipe）：半双工，用于父子进程通信，父进程在内核开辟一块缓冲区，得到两个文件描述符分别指向两端，子进程同理，然后父进程关闭读端进行写操作，子进程关闭写端进行读操作从而实现了两个进程的通信。

有名管道（FIFO）：半双工，相比管道添加了一个路径名从而可以使两个不相关的进程进程通信，也可以跨机器通信。

信号（signal）：类似于软中断，如果进程接受到了信号，就相当于发生了中断，这时候进程会切换到内核态去执行信号处理函数。进程之间可以通过系统调用互相发送信号，也可以在收到信号时做相应的回调。信号是类型是系统中事先定义好的，我们可以在发送某些特殊的信号加一些参数。

消息队列：系统提供的一种机制，可以从一个进程向另一个进程发送自定义的消息，这些消息会被放到一个特殊的内存区域，可以通过一个指针获取。多个消息的指针会构成一个队列，被内核管理着，其他进程可以从这个队列里面获取消息数据。

共享内存：通过系统调用开辟一块特殊的内存，然后映射到不同的进程上面，这样不同的进程在访问这一块内存的时候都可以像访问自己用户区内存一样，从而实现通信。

信号量：内核实现的一种特殊的对象，由操作系统赋予其控制进程状态的特性，信号量的值表示有几个任务可以访问该信号量所保护的共享资源。二进制信号量是信号量的一个子集，通过PV操作实现访问资源线程的互斥（实现临界区）。

套接字（socket)：常用于跨机器通信，属于应用层与传输层的一个连接媒介。


