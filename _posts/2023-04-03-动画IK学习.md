---
title: 日常备忘
tags: GamePlay
categories: 日常
---

<!-- TOC -->

## 基本概念（暂时省略）
## **逆运动学(一): 二维逆运动学，两根骨胳**
https://zhuanlan.zhihu.com/p/354925040   好理解 直接放链接
## **逆运动学(二): 二维逆运动学，多于两根骨胳**
当我们处理多于两根骨胳的ＩＫ问题，之前方法是有不足的。我们可以梯度下降(Gradient Decent）
### **梯度下降(Gradient Decent)**
理解梯度下降原理的最简单方法是把他想为山坡。我们开始在一个随机的位置，我们想走到最低点。在每一步，梯度下降告诉你向降低高度的方向移动。如果地形的几何结构相对简单，这种方法会向谷底收敛。

在这个示例中我们有一个函数，它接受单个参数（X轴），并返回一个ErrorFunction（Y轴）。从X轴上的随机点开始，梯度下降应该迫使我们朝着最小值的方向移动。

从整体上看前进的方向是解决了。不幸的是，梯度下降事先不知道最小值在哪里。该算法所能做的最好的猜测是沿着斜率的方向移动，也称为函数的梯度。如果你在一座山上，让一个球去，并跟随它到达山谷。下图显示了误差函数在两个不同点的梯度  
![image](https://pic2.zhimg.com/80/v2-aebf9b6b4f8aa3e1044b06f0b029f299_720w.webp)  
从整体上看前进的方向是解决了。梯度下降事先不知道最小值在哪里。该算法所能做的最好的猜测是沿着斜率的方向移动，也称为函数的梯度。如果你在一座山上，让一个球去，并跟随它到达山谷。下图显示了误差函数在两个不同点的梯度  
**以上为摘抄**  
简单理解  梯度下降不就是夹逼定理吗（夹你夹你）
### **梯度估计**
如果你以前学过微积分，你可能知道函数的梯度与其导数有着密切的联系。然而，计算导数需要函数满足某些数学性质，而这些性质通常不能保证用于任意问题。此外，导数的解析推导需要解析地给出误差函数。同样，您并不总是能够访问您试图最小化的功能的分析版本。

在所有这些情况下，都不可能得到函数的真导数。解决办法是粗略估计它的价值。下图显示了如何在一维中实现这一点。通过对附近的点进行采样，可以得到函数局部梯度的感觉。如果左边的错误函数较小，则转到左边。同样，如果右边的小一些，你就往右边走。

此采样距离(Sample Distance)在称为 $\Delta$x
 ，了解梯度下降是如何工作的，数学上是怎的呢？第一步是计算误差函cost function，ｆ

在特定点p 的梯度，我们需要的是找到函数增长的方向。函数的梯度与其导数密切相关。

ｆ的导数叫做 ｆ＇它在p点的值是f'(p），它指示函数的增长速度。常数 
 通常被称为学习速率，它决定了我们逆着梯度移动的速度。值越大，解决方案的速度越快，但也越有可能實際值。


## **逆运动学(三): 梯度下降实现**
https://zhuanlan.zhihu.com/p/355709979

## **逆运动学(四): 循环坐标下降实现 (Cyclic Coordinate Decent)**
https://zhuanlan.zhihu.com/p/358065064

## **逆运动学(五): Jacobian Matrix**



