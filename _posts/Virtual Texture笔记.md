[TOC]
https://zhuanlan.zhihu.com/p/138484024  浅谈Virtual Texture  
https://www.bilibili.com/video/BV1KK411L7Rg  irtual Texture（虚拟纹理）的理解和应用 | Epic 李文磊  
https://zhuanlan.zhihu.com/p/143709152 游戏引擎随笔 0x14：UE4 Runtime Virtual Texture 实现机制及源码解析
https://www.zhihu.com/question/453803452/answer/1828213316 Virtual Texture的意义是什么？  
https://zhuanlan.zhihu.com/p/85417843基于Unity3D引擎的大地形加载研究  

https://zhuanlan.zhihu.com/p/148283184 Virtual Texture in Modern Graphics API

### Virtual Texture 
纹理映射用于将表面细节添加到几何图元中，能更有效的管理和渲染表面细节。

![image](https://pic2.zhimg.com/v2-2960d582ae552b480d44746b4f109245_r.jpg)  
由于要进行对象分析，将纹理流送网格化，以及从收集到的纹理网格集（Physical Texture）中进行采样，在仅流送方面虚拟纹理会比传统纹理的消耗更大一些，根据屏幕内容的变化速率不同，该消耗可能在1~3ms之间。  
消耗总是相对的，虚拟纹理能够在某些时候带来远超流送消耗的效率收益，比如将超大范围的多层地表纹理烘焙为运行时虚拟纹理，将每帧都要执行的复杂层计算转变为对纹理的直接采样，能够节省大量性能消耗。

Virtual Texture的意义是什么？  

之前看的Unity中使用RVT的工程都是在CPU端建立索引的，这其实完全没有发挥出VT的优势，最大最明显的点在于Texture Streaming可以从原来的纯CPU运算交给GPU了，这是因为所有Shader都可以使用统一的虚拟坐标，这就意味着可以直接由屏幕信息反推出当前用到的贴图，这是传统的渲染管线难以比拟的地方，根据后续的学习了解到索引的建立是可以直接建立到GPU中，通过Multi-Indirect Draw配合Compute Shader完全可以实现。

假如我们的地表纹理是通过多种纹理混合而来的化，我们需要一张叫做splat map的图来记录我们每个纹理的权重，一般splat map有RGBA四个权重，可以存储4个混合纹理，如果超过的化就需要更多的splat map 记录，这样在渲染一块地表时会采样许多次，有很大的开销，而Virtual Texture可以允许所有表面以单批几何绘制。不同的表面可以使用不同的
部分相同的虚拟纹理，并且不需要每个表面纹理选择。  

我们需要和传统mipmap的载入方式对比才可以看出vt的有点，mipmap占用内存多除了载入的多以外，还有就是在场景中渲染的多，尤其在遮挡多的场景中更是如此，这是为了避免物体突然出现在摄像机中，所以cull做的十分保守，一般都会将整个物体渲染出来。但是在vt中很少有这个问题，以为他将我们的map进行了切片，在在我们不能即时渲染所需的比较高的层级时，可以使用底层级的短暂的替代，所以在vt中cull可以更加彻底，同样，因为频繁的physic texture切换，io压力会较大，所以如果想使用vt，一般要预留1-3ms的io消耗时间，这是一种时间换内存的思路，所以我们要尽量当有大量高分辨率纹理，耗费内存的情况下使用。这样vt的优势才更明显

- Virtual Texture的意义不仅是带宽和内存的问题，还可以显著提高渲染效率，之前对于纹理混合采用的是多次渲染的形式，多次对drawcall调用，效率过低，现在可以将超大的多层地表纹理烘培为运行时纹理，或者通过流载入的方式，将每帧都要执行的复杂的计算转化为直接的采样，能够节省大量性能消耗。
- 除了性能上的提高外，在对地形纹理的表现上也有优势，因为任何物体的shader可以使用绝对坐标获VT坐标，所以易于实现一下沙石交融的效果，获取高度信息，使草从资源种到地上而不是天空，对于坐标获取可以参考megaTexture的概念，一个虚拟的巨型的完整的纹理资源，所以不同与传统的Texture平铺，所以每一个texture资源都可以获取一个具体的坐标信息，由此可以实现高度混合，来实现一些边缘效果的混合，以及各种各样的效果。  ![image](https://pic1.zhimg.com/80/v2-9be54785778d8e88853317abc9de2a08_1440w.jpg)  
很明显石头是一个模型，而这个模型的材质却需要和地面完美融合，在传统的地形系统中要想实现这套系统不仅非常麻烦，而且很可能造成额外消耗：如果使用Pixel Offset，就会破坏Early Z，在某些硬件上甚至可能导致性能骤降，如果使用二次叠加，那石头的Shader可能会过于复杂，而且功能耦合十分严重。而对于Virtual Texture Terrain来说这基本可以说不是问题了，我们只需要将世界坐标到UV坐标的转换变量作为Uniform传递进Shader：
- 通常我们为了减少drawcall通常使用合批的方式，比如我们将一整个房子的Texture进行合批，但是当我们在房子内部空间的时候，视角只占很小一部分Texture，但还是会将整个Texture载入到内存，而如果使用Virtual Texture的方式，就很大程度上解决了我们的问题。
- 多象限UV：我们制作好Virtual Texture后，还需要在模型UV标记匹配，当我们的VT超出限制后，原有的UV只是0到1之间无法表示，可以使用多个UV象限进行精准的匹配。
- 均一化贴图内存的占用
在MegaTexture的基础上，id Software进一步提出了Virtual Texture的概念，这个概念取自于Virtual Memory,与虚拟内存类似的是，一个很大的Texture将不会全部加载到内存中，而是根据实际需求，将需要的部分加载。与虚拟内存不同的是，它不会阻塞执行，可以使用更高的mipmap来暂时显示，它对基于block的压缩贴图有很好的支持。  
基本思路是，会将纹理的mipmap chain分割为相同大小的tile或page,这里的纹理叫虚纹理，然后通过某种映射，映射到一张内存中存在的纹理，这里的纹理是物理纹理，在游戏视野发生变化的时候，一部分物理纹理会被替换出去，一部分物理纹理会被加载。 
![image](https://pic4.zhimg.com/80/v2-8dd6e9e7750884bbab8d6da5fe221ec3_720w.jpg)
这样的机制不仅仅减少了带宽消耗和内存（显存）消耗，也带来了其他好处，比如有利于合批，而不用因为使用不同的Texture而打断合批，这样可以根据需求来组织几何使得更利于Culling，当然合批的好处是states change 变少。LightMap也可以预计算到一张大的Virtual Texture上，用来合批。  

运行过程概述
#### VT数据准备阶段
1. Feedback Rendering  先渲染一边场景，然后根据屏幕上每一个像素使用的虚拟UV坐标获取使用的page以及mipmap等级，然后将信息存储到buffer中然后回传给cpu更新Texture对应的page   
其实Virtual Texture的贴花是基于正交摄像机投影的一套独立的非常轻量的管线，相当于Deferred Shading的Geometry Pass，只不过输出的目标不是屏幕而是VT而已
2. 生成VT纹理数据，更新到指定VT Physical，这就是在预渲染截断 
3. 再根据feedback数据更新PageTable，这样就完成了page的更新，Physical Texture 可以通过pageTable 索引到正确的Texture

#### VT数据采样阶段
1. 根据屏幕坐标以及相关信息生成VT Physical Texture UV
2. 对VT Physical Texture执行采样


传统贴图的并没有将Texture划分为page，所以加载时是直接加载整个mip。
虚拟贴图将我们的Texture进行划分小的page，在加载时是获取page信息后，将page对应的Virtual Texture 块加载到Physical Texture中。   
Virtaual Texture相对减少了我们的内存压力，但是提高了我们的IO压力，并且因为page大小的限制，我们最多只能由4层的mip，而传统贴图可以有更多层。  
并且在混合的时候，SVT和RVT都是不支持多Page渲染，所以是每一帧随机渲染来实现的，会有细微的闪烁，而传统贴图支持多page渲染，所以渲染完成后page不会发生替换。


#### 地址映射
##### 四叉树映射
使用四叉树主要是为了和mipmap对应，也就是每个低mip的map会对应有四个高mip的map，
这样可以动态调整运行时的分辨率，来调整我们的性能指标。这里的对应关系就是每个加载的Virtual Texture的page对应一个四叉树的节点，具体的计算如下：
![image](https://pic1.zhimg.com/80/v2-754fb67195882775cb95dcb1d2366ad8_720w.jpg)

##### 单像素对应虚纹理的一个page的映射
如果我们的索引像是操作系统中的多级页表一样，那么频繁的索引操作会降低我们的效率，
这个方案就是将每一个像素都对应一个page，这样确保我们一次索引就能检索到page，假如对应的mip没有加载，存储的就是高mip的转换信息。这样显然就提高了地址转换的效率，但是，带来了内存增加。  
我们需要每个虚纹理的page都对应一个texel。其中bias和scale都是2维的向量，即使设计虚纹理和物理纹理的比例一致，我们也需要至少scale,Sbias,Tbias三个量，而且这三个量的精度要求很高，至少需要16bit的浮点数精度，如果要达到这样的精度就需要，F32*4的纹理格式，那就会产生一个巨大的映射纹理，需要减小映射纹理的大小。

##### 双纹理映射
方案类似单像素对应，但是存储的是物理纹理的坐标，用这个坐标在另外一张texture上索引
这样的优点是将page中为了和物理纹理比例一致而设置的三个量，转化为简单的坐标，四叉树上面的节点信息以及层级信息，都通过一张Texture中的坐标信息表示出来，表现就是虚拟纹理对应的texture的样子的分辨率，想一个鹦鹉螺一样卷起来。  
![image](https://pic3.zhimg.com/80/v2-059d668ec48484ab740719aa662be7fa_720w.jpg)
这样一来，就减少了映射纹理的大小了，但是同时带来了多一次的纹理查询。

#####  page和mip level映射
总结上面两个基于映射纹理的方案，要么是纹理需要很大的存储，要么是需要多次查询。如果从映射纹理比较大的角度考虑优化的话，可以考虑适当减少每个像素的大小

#### Texture Filtering（纹理过滤）

https://learnopengl-cn.github.io/01%20Getting%20started/06%20Textures/    LearnOpenGL

由于虚拟纹理并没有完整加载，所以各种采样过滤在page的边界会有问题，我们需要自己设计解决这些问题的方法，适当的使用软实现的采样。

之所以需要纹理过滤是因为纹理坐标的设置并不依赖纹理像素，所以我们在根据纹理坐标进行采样的时候就需要进行过滤处理

GL_NEAREST（也叫邻近过滤，Nearest Neighbor Filtering）是OpenGL默认的纹理过滤方式。当设置为GL_NEAREST的时候，OpenGL会选择中心点最接近纹理坐标的那个像素。下图中你可以看到四个像素，加号代表纹理坐标。左上角那个纹理像素的中心距离纹理坐标最近，所以它会被选择为样本颜色：

![](https://learnopengl-cn.github.io/img/01/06/filter_nearest.png)

GL_LINEAR（也叫线性过滤，(Bi)linear Filtering）它会基于纹理坐标附近的纹理像素，计算出一个插值，近似出这些纹理像素之间的颜色。一个纹理像素的中心距离纹理坐标越近，那么这个纹理像素的颜色对最终的样本颜色的贡献越大。下图中你可以看到返回的颜色是邻近像素的混合色：

![](https://learnopengl-cn.github.io/img/01/06/filter_linear.png)

那么这两种纹理过滤方式有怎样的视觉效果呢？让我们看看在一个很大的物体上应用一张低分辨率的纹理会发生什么吧（纹理被放大了，每个纹理像素都能看到）：

![](https://learnopengl-cn.github.io/img/01/06/texture_filtering.png)

GL_NEAREST产生了颗粒状的图案，我们能够清晰看到组成纹理的像素，而GL_LINEAR能够产生更平滑的图案，很难看出单个的纹理像素。GL_LINEAR可以产生更真实的输出

当进行放大(Magnify)和缩小(Minify)操作的时候可以设置纹理过滤的选项，比如你可以在纹理被缩小的时候使用邻近过滤，被放大时使用线性过滤。

#### Feedback Rendering
feedback Renderer是通过在渲染时，求偏导，得到相邻像素UV的插值的方式来计算mipmap Level的等级，再由cpu从GPU中回读获取

在Virtual Texture中一个很重要的事情是要有一个可以决定加载哪些page的策略，这个策略就是要有一个叫Feedback Rendering的过程。这个可以设计为一个单独的pass，或者跟Pre-Z或者GBuffer同时。渲染生成的这张texture里面存的就是虚纹理的page坐标，mip level和可能的虚纹理id（用来应对多虚纹理的情况）。
![image](https://pic1.zhimg.com/v2-d74b3fb551b162d4fadb0fb82c299560_r.jpg)
可以看到上图，由于page的变化在屏幕空间是比较低的，所以Feedback的RT是不需要全分辨率的，低分辨率渲染就可以了。   
对于半透明物体或者alpha test的物体，feefback只能当作不透明物体渲染，那样就会屏幕像素上随机产生当前像素的结果。具体可能就是刚加载的page，下一帧肯就会被替换，导致物理纹理一直在置换，即便屏幕像素并未改变，物理纹理的page也无法稳定下来。为了解决这个问题，需要设计一个调色板，对于半透明物体，间隔出现全透明或者不透明，对于多page的情况，则需要设计为间隔出现不同page的结果，这样就能同时加载所有page，并且保持稳定。

#### Texture Poping
由于page是异步加载的，这是有延时的，当加载的mip比当前显示的差很远的时候，我们渲染会使用新加载的更清晰的mip,这样我们会看到非常明显的跳变。假如我们用了软实现的Tri-linear Filtering，那么当加载的mip level跟当前显示的mip level相差很大的时候，需要做一个delay，等待中间的mip page的加载，然后再去更新。对于没有Tri-linear Filtering的实现，就得逐渐更新page，使得过度平滑。一个可能的方法是，upsample低分辨率的mip，直到高分辨率的mip加载。但是，这样仍然会出现跳变，由于采样的位置其实发生了突变。  
![image](https://pic1.zhimg.com/80/v2-7019ba61ac6c2607e994096ede9a6aa0_720w.jpg)





### SVT

- 按需将纹素数据缓存于内存中。
- 在硬盘中烘焙和加载纹素数据。
- 非常适用于生成时间较长的纹理数据，如光照贴图或美术师创建的大型细节纹理。  
便于在硬盘烘培和加载纹理  

### RVT
- 按需将纹素数据缓存于内存中。
- 运行时由GPU生成的纹素数据。
- 非常适用于可按需渲染的纹理数据，如过程纹理或合成分层材质。
提高渲染效率， 贴画效果

Runtime Virtual Texture  
可有效渲染过程生成或分层的复杂材质，使运行时虚拟纹理适用于渲染复杂的地形材质。其能改善地形样条、网格体和材质贴花，及一般地形与对象混合的渲染性能和工作流程。  
简单来说就是不仅进行纹理的渲染，还改善地形样条、网格体和材质贴花，及一般地形与对象混合，是一套可以场景交互的渲染工作流程。  
运行时虚拟贴图，避免加载太多的贴图信息，所以来用了虚拟内存的方式，通过映射，减少了载入内存中的贴图大小。  
增加了材质之间的交互  
- 实例1：在地形材质上实现树的影子，可以通过RVT实时采样到树的材质信息，再通过RVT混合原始地形材质和影子材质
- 实例2：对地面材质采样，和石头本身材质混合，实现不同地形下石头材质表象不同。
- 实例3：高度影响，草的模型较大，在某些地形上悬浮出来，通过采样地面高度，和本身材质混合，达到和地面贴合的效果
- 优化：SVT io开销 RVT 运行时采样开销
- RVT在中远距离使用SVT，或者去掉远处mip
- 减少数量和被拍物体复杂度 哪个层级mip不会被拍



# 到底是时间换空间还是空间换时间

时间换空间的依据：VT因为内存不会常驻，所以在纹理加载上会有更多的开销，纹理内存减少。

空间换时间的依据：26张贴图合并成2张render target，减少需要采样的贴图

以RVT为例子，常提及空间换时间，因为在PBR大量使用的现在，一层地形图层采样的纹理数变多

- 8层在十年前你可以认为是8张颜色贴图加两张控制图的混合，十张，好像是有点多，但是现在是PBR的时代,以Unity的Terrain材质为例8层意味着

（1 Albeto + 1 Normal + 1 Detail[AO R + Metal G + Roughness A]）* 8 + 2 Control Map = **26次贴图采样**

即每个像素，每帧都会有26次贴图采样。这就是为什么Unity官方推荐移动平台不要超过4层的原因。你以为4层就没事了吗？这个标准只能保证中端设备能跑30帧且烫不烫完全不care。



解答：SVT时间换空间，RVT空间换时间

想要理解首先要清楚两种Texture的生成方式，SVT即Streaming流加载的方式，在Runtime之前提前将需要采样的Texture合并，然后在使用的时候通过精确加载mipmap，这样即可以减少采样次数也可以减少内存，但是IO压力会变大。RVT即Runtime生成VT，因为是RunTime生成的，肯定是常驻内存的，这样减少采样次数，也避免了频繁加载的问题，但是内存占用会变大。

这时思考下，现在内存的容量越来越大，价格越来越低的情况下，是不是不用再内存上太过节省了，游戏公司也确实不会在内存上进行优化，占用内存越来越大。所以是否应该重新思考下VT的最大作用还是像虚拟内存那样节省空间呢？

有人认为“通过使用VT，物理空间分离的两张贴图可以使用统一连续的UV。”也有解释是为了解决“平铺贴图的分辨率远超物理内存的承受能力”这个问题它的核心在于Virtual，也就是在GPU中通过一个中间索引层，将统一的虚拟地址转换为实际地址，读取贴图。至于中间这个索引层是什么形式的，这还真无所谓。譬如开发高度图大地形时，要求使用世界坐标当UV读取贴图，这时候索引层就必须是Texture2D格式以达到连续坐标的目的，这就是两个target render texture，而之前提到RVT的一些贴画和纹理过度的效果，都是因为这样的索引关系达成的，同样的我们在地形系统上不同的图层上贴上不同的贴图，一般形式下我们需要对每个图层进行采样，需要根据UV坐标去对应贴图进行采样，在PBR的方式下因为单一图层需要采样的贴图变多，我们需要采样的贴图会变成几十层，所以地形图层一多，我们采样的时间开销就变得十分多，那么我们能不能对这些贴图进行合并减少采用次数吗？当然可以，这就是VT最重要的职责，把每块的26张贴图合并成2张render target，这样我们渲染的时候不管有多少图层到了渲染的时候都只有2个贴图采样，但是显存必然是有更大的开销的，空间换时间不多废话。

所以说在使用RVT的时候，我们的修改可以直接显示出来，不需要再去二次烘培。